<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Author Identification using different classification methods</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/round-about.css" rel="stylesheet">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-inverse navbar-fixed-top" role="navigation">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="#">Cloud Project Group 9</a> 
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav">
                  
                    <li>
                        <a href="index.html">Overview</a>
                    </li>
                    <li>
                        <a href="motive.html">Motivation</a>
                    </li>
                    <li>
                        <a href="implem.html">Implementation</a>
                    </li>
                     <li>
                        <a href="data.html">Dataset</a>
                    </li>
                    <li>
                        <a href="perform.html">Performance</a>
                    </li>
                    <li>
                        <a href="results.html">Results</a>
                    </li>
                     <li>
                        <a href="accomp.html">Accomplishments</a>
                    </li>
                    <li>
                        <a href="roles.html">Roles</a>
                    </li>
                     <li>
                        <a href="ref.html">Observations and External References</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Content -->
    <div class="container">

        <!-- Introduction Row -->
        <div class="row">
            <div class="col-lg-12">
                <h1 class="page-header">
                    <small>Author Identification using different classification methods</small>
                </h1>
                <p>
                    CS Graduate Students at University of North Carolina Charlotte
                </p>
            </div>
        </div>

        <!-- Team Members Row -->
          <div class="row">
            <div class="col-lg-12">
                <h2 class="page-header">Our Team</h2>
            </div>
            <h3>Allen Sylvester Irudayaraj</h3>
            <h3>Advaith Auron Suresh</h3>
            <h3>VenkateshPerumal Chockalingam</h3>
           
        </div>
        <div class="container">
        <h1>Implementation</h1>
        <p>
        <ul>
        <li>
            <b>Logistic Regression</b>
            <ul>
            <li> We have implemented a standard logistic regression model in this project. We aim at obtaining weights which could maximize the likeliness or likelihood of obtaining our data and model it in such a way that it is able to clearly distinguish the target values. We use the concept of maximum likelihood estimation to obtain the result. The problem of optimization is resolved using gradient ascent as the maximization of likelihood in logistic regression is devoid of a closed form solution.  
            </li>
            <b>Processing Steps</b>
            <li>
            We would be providing classification results for each author and approach the problem as a 2-class classifier and not a k-class classifier. The result would hence be of the form: Document belongs to the author or Document does not belong to the author. We then bifurcate the data into a training set (70%) and a test set (30%). We train the logistic regression model on the training set and predict the outcome based on the test set. 
            </li>
            <b>Data Preparation</b>
            <li>
           The data obtained from the dataset is processed before feeding it to the model. We use RDDs to separate files belonging to one class from the others. We then obtain our training data and test data by randomly splitting it. 
First, we obtain each file as a key value pair containing the filename and its contents as a key and value pair. We iterate through the document corpus for our desired class and model a dictionary of the words used in it. We use a CountVectorizer function defined in the sklearn library to achieve this and obtain a term frequency of words used in each document of the entire training corpus. As a result, we obtain a feature matrix containing the frequency count of each word in a document.
We use the CountVectorizer function along with some options that allow us to prepare our data for better modeling. The parameters given were:
            <b>Input = ‘content’:</b>
            the input is expected to be the sequence strings or bytes items are expected to be analyzed directly
            <b>stop_words = ‘english’:</b>
            If ‘english’, a built-in stop word list for English is used
            <b>lowercase = True:</b>
            Convert all characters to lowercase before tokenizing
            <b> max_df = 0.6:</b>
            When building the vocabulary, ignores terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts
            <b> min_df = 5: </b>
            When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold.
            <b> max_features = 1000: </b>
            If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus
            <b> Sample Data: </b>
            The following are a few lines from “Anthony Trollope__A Ride Across Palestine”

Circumstances took me to the Holy Land without a companion, and compelled me to visit Bethany, the Mount of Olives, and the Church of the Sepulchre alone.  I acknowledge myself to be a gregarious animal, or, perhaps, rather one of those which nature has intended to go in pairs.

            </li>
            <b>Maximum Likelihood:</b>
            <li>
            To obtain the maximum likelihood, we use log likelihood as log transformations are monotonic and do not affect weight parameters. We define log-likelihood as a cumulative sum of the training data.
It is given by the equation:

where xi is the feature data, β is weight and y is the target

To obtain the gradient of the log-likelihood, we take a derivative of the given equation and represent it in the form of a matrix, that gives us:

            </li>
            </ul>

        </li>
        <li> <b>K Nearest Neigbors</b>
        <ul>
        <li>
            <p><b>Steps Followed for implementation</b></p><br>
            <ol> <li>TFIDF scores of all unique words is computed for each Author in training corpus. </li> 
<li>TFIDF scores of all unique words is computed for each author in test corpus.</li>
<li>Euclidean distance is calculated by comparing the selected test document TFIDF scores with TFIDF scores of each document present in the training set.</li>
<li>The documents are ranked in ascending order.</li>
<li>K value is selected, and first K number of documents are selected from the ranked list.</li>
<li>Author with highest number of document in the K list, classified as author for the test document selected.
</li>
            </ol> <br> <br>
            
        </div>

        <hr>

        <!-- Footer -->
        <footer>
            <div class="row">
                <div class="col-lg-12">
                    <p>Copyright &copy; Face Matching 2017</p>
                </div>
                <!-- /.col-lg-12 -->
            </div>
            <!-- /.row -->
        </footer>

    </div>
    <!-- /.container -->

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

</body>

</html>
